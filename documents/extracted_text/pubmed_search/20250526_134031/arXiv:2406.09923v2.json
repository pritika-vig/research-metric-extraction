{
  "paper_id": {
    "doi": null,
    "arxiv_id": "2406.09923v2",
    "pmcid": null,
    "pmid": null
  },
  "paper_title": "uploads/clibench:_a_multifaceted_and_multigranular_evaluation_of_large_language___models_for_clinical_decisi.pdf",
  "paper_gc_uri": "gs://patient-engagement-pipeline-bucket/uploads/clibench:_a_multifaceted_and_multigranular_evaluation_of_large_language___models_for_clinical_decisi.pdf",
  "source_url": "http://arxiv.org/pdf/2406.09923v2",
  "fields": [
    {
      "name": "Title",
      "description": "Full title of the study as stated in the paper",
      "value": "CLIBENCH: A MULTIFACETED AND MULTIGRANULAR EVALUATION OF LARGE LANGUAGE MODELS FOR CLINICAL DECISION MAKING",
      "evidence_quote": "\"CLIBENCH: A MULTIFACETED AND MULTIGRANULAR EVALUATION OF LARGE LANGUAGE MODELS FOR CLINICAL DECISION MAKING\"",
      "page_number": 1
    },
    {
      "name": "Author(s)",
      "description": "List of all authors involved in the paper, in order of appearance",
      "value": "Mingyu Derek Ma, Chenchen Ye, Yu Yan, Xiaoxuan Wang, Peipei Ping, Timothy S Chang, Wei Wang",
      "evidence_quote": "N/A",
      "page_number": 1
    },
    {
      "name": "Patient Co-authors",
      "description": "Were any co-authors identified as patients or caregivers?",
      "value": "No",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Journal",
      "description": "Name of the journal where the study was published",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Publication Stage",
      "description": "Indicate if the paper is peer-reviewed, a preprint, or another stage",
      "value": "Preprint",
      "evidence_quote": "\"arXiv:2406.09923v2 [cs.CL] 11 Oct 2024\"",
      "page_number": 1
    },
    {
      "name": "Publication Date",
      "description": "Official date the paper was published",
      "value": "October 11, 2024",
      "evidence_quote": "\"arXiv:2406.09923v2 [cs.CL] 11 Oct 2024\"",
      "page_number": 1
    },
    {
      "name": "Field of Study",
      "description": "Disciplinary or clinical field, such as primary care, oncology, or public health",
      "value": "Artificial Intelligence in Healthcare",
      "evidence_quote": "\"The integration of Artificial Intelligence (AI), especially Large Language Models (LLMs), into the clinical diagnosis process offers significant potential to improve the efficiency and accessibility of medical care.\"",
      "page_number": 1
    },
    {
      "name": "Country",
      "description": "Country or countries where the study was conducted or primarily situated",
      "value": "USA",
      "evidence_quote": "\"We extract clinical data elements as the foundational information units by cross-referencing multiple tables of the hospital and note modules of the MIMIC-IV dataset (Johnson et al., 2023), which contains hospital-wide Electronic Health Records (EHR) from 2008 to 2019 at the Beth Israel Deaconess Medical Center in Boston.\"",
      "page_number": 4
    },
    {
      "name": "Type of Article",
      "description": "Classify the article: original research, protocol, review, commentary, etc.",
      "value": "Original Research",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Aim of Study",
      "description": "State the main purpose or objective of the study as described by the authors",
      "value": "To introduce CLIBENCH, a novel benchmark for evaluating Large Language Models (LLMs) in clinical diagnosis, addressing gaps in existing evaluations by offering a comprehensive and realistic assessment of LLMs' capabilities.",
      "evidence_quote": "\"To address these gaps, we introduce a novel benchmark, CLIBENCH, aimed at a more accurate and inclusive assessment of LLMs' capabilities within the realm of clinical diagnosis.\"",
      "page_number": 2
    },
    {
      "name": "Key Findings",
      "description": "Summarize the main results or conclusions of the study",
      "value": "The study's preliminary results highlight the strengths and weaknesses of current LLMs in making clinical decisions, offering insights into areas for further research and development in LLM-powered healthcare.",
      "evidence_quote": "\"Preliminary results from these experiments highlight the strengths and weaknesses of current LLMs in making clinical decisions, offering insights into areas for further research and development.\"",
      "page_number": 2
    },
    {
      "name": "Patient/Public Engagement (Y/N)",
      "description": "Does the study report any meaningful or intentional involvement of patients or the public in any phase of the research or implementation?",
      "value": "No",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Type of Engagement (Montreal Model continuum)",
      "description": "Categorize engagement based on the Montreal Model: Information (e.g., newsletters), Consultation (e.g., surveys, focus groups), Collaboration (e.g., co-design sessions), or Partnership (e.g., decision-making roles, advisory boards).",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Level of Patient Involvement (Montreal Model)",
      "description": "At what level were patients or the public involved across the research lifecycle? Score each phase (design, development, evaluation, implementation) as: None, Information, Consultation, Collaboration, or Partnership.",
      "value": "None",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Evaluation of Impact (Y/N)",
      "description": "Did the study evaluate or measure the effect of patient/public engagement?",
      "value": "No",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Type of Evaluation",
      "description": "What type of method or framework was used to evaluate the impact of engagement (e.g., metrics, qualitative feedback, evaluation framework)?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Impact of Engagement",
      "description": "Describe any outcomes or changes attributed to patient/public engagement (e.g., design changes, improved recruitment, insights).",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Participatory Process",
      "description": "Did the study include a participatory design process such as workshops, co-design, or stakeholder sessions?",
      "value": "No",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Continuous Evaluation Cycles",
      "description": "Was engagement conducted iteratively or cyclically, with feedback loops or repeated interaction?",
      "value": "No",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Implementation",
      "description": "Did patient/public engagement influence the implementation strategy or process of the research?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Organization of Health Care",
      "description": "Did engagement lead to reported changes in health care delivery, systems design, or institutional practice?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Persuasive Design Techniques",
      "description": "Were behavior-change strategies or persuasive technologies mentioned (e.g., nudges, gamification, reminders)?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Assess Impact",
      "description": "Did the study measure outcomes or success metrics related specifically to engagement efforts?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Information",
      "description": "Was information provided to patients/public about the study, without involving them in decision-making?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Consultation",
      "description": "Was patient or public input sought (e.g., through interviews, surveys, focus groups), without involving them in decision-making?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Collaboration",
      "description": "Was there shared decision-making or co-design between researchers and participants in any phase of the study?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Partnership",
      "description": "Were patients/public involved across all stages with formal roles (e.g., co-authors, advisory board, project governance)?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Equity or Inclusivity Considerations",
      "description": "Did the study aim to include marginalized or underrepresented groups in the engagement process?",
      "value": "Yes",
      "evidence_quote": "\"Additionally, regarding patient attributes, the evaluation set exhibits a fair gender distribution, while still having an unbalanced distribution for races and insurance types as shown in Figure 1(c)(d)(e), because the source data inherently exhibits significant disparities in representation (Ma et al., 2024a).\"",
      "page_number": 6
    },
    {
      "name": "Ethical, Legal, and Social Implications (ELSI)",
      "description": "Did the study address privacy, informed consent, data ethics, or cultural relevance in its engagement or implementation approach?",
      "value": "Yes",
      "evidence_quote": "\"We use Azure OpenAI service and opt out of human review of the data to prevent third parties' data access, following the MIMIC data publisher's suggestion and complying with the data use agreement.\"",
      "page_number": 7
    },
    {
      "name": "Technology Complexity / Integration Readiness",
      "description": "Did the study evaluate how complex the technology was or how well it integrated with existing clinical or community workflows?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    },
    {
      "name": "Real-World Evaluation or Deployment",
      "description": "Was the technology evaluated or deployed in real-world settings beyond pilot studies or lab prototypes?",
      "value": "The benchmark is based on real clinical cases from the MIMIC-IV dataset.",
      "evidence_quote": "\"Meticulously curated from the MIMIC IV dataset (Johnson et al., 2023), our benchmark spans a broad spectrum of cases across various specialties, enriched by a connection to a structured expert-curated diagnosis ontology, the ICD-10-CM coding (icd, 2023a) for precise and hierarchical evaluation.\"",
      "page_number": 2
    },
    {
      "name": "Feedback and Iterative Adaptation",
      "description": "Was feedback from participants used in an ongoing way to adapt the design, strategy, or evaluation?",
      "value": "N/A",
      "evidence_quote": "N/A",
      "page_number": null
    }
  ]
}